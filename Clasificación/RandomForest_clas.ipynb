{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://www.freecodecamp.org/news/content/images/2020/08/how-random-forest-classifier-work.PNG\" width=\"350px\" height=\"180px\" />\n",
    "\n",
    "\n",
    "# <font color= #8A0829> Laboratorio de Modelado de Datos </font>\n",
    "- <Strong> Flavio Maximiliano Herrada Avalos</Strong>\n",
    "- <Strong> Año </Strong>: 2021\n",
    "- <Strong> Email: </Strong>  <font color=\"blue\"> `flavio.herrada@iteso.mx` </font>\n",
    "___\n",
    "\n",
    "<p style=\"text-align:right;\"> Imagen recuperada de: https://www.freecodecamp.org/news/content/images/2020/08/how-random-forest-classifier-work.PNG</p>\n",
    "\n",
    "### <font color= #2E9AFE> Tema: Modelos basados en Árboles Parte II - Clasificación</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bosques Aleatorios\n",
    "\n",
    "\"Los árboles tienen un sólo aspecto que previene que sean la herramienta ideal para el aprendizaje predictivo, que es la **inexactitud**\" \n",
    "\n",
    "Pasos para crear un bosque aleatorio:\n",
    "- Crear un dataset \"bootstrapped\"\n",
    "- Crear un árbol de decisión usando el dataset \"bootstrapped\", pero sólo usar un subconjunto aleatorio de variables (o columnas) en cada paso. \n",
    "- Regresar al paso 1. y repetir \n",
    "\n",
    "Gracias al proceso de bootstrapping, el requerimento de dividir los datos en prueba y entrenamiento no es tan estricto. Se recomienda dividir los datos en prueba y entrenamiento cuando se quiere comparar su desempeño contra otros modelos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import (accuracy_score,precision_score,recall_score)\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar la base de datos\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "\n",
    "plt.scatter(X[:,0],X[:,1], c=Y, s=10, cmap=plt.cm.rainbow,zorder=2)\n",
    "plt.xlabel('x_p1')\n",
    "plt.ylabel('x_p2')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2,\n",
    "                                                    random_state=0,\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Construccion y entrenamiento de la bolsa de modelos\n",
    "modelo = RandomForestClassifier(n_estimators=100,\n",
    "                               criterion='gini',\n",
    "                               max_depth=10,\n",
    "                               min_samples_split=2,\n",
    "                               min_samples_leaf=1,\n",
    "                               max_features='auto',\n",
    "                               bootstrap=True,\n",
    "                               oob_score=False,\n",
    "                               random_state=0,\n",
    "                               verbose=1)\n",
    "\n",
    "start_time = time.time()\n",
    "modelo = modelo.fit(X_train,y_train) # prediccion con la bolsa de modelos\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "Yhat = modelo.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluacion del modelo\n",
    "accu = accuracy_score(y_test,Yhat)\n",
    "prec = precision_score(y_test,Yhat,average='weighted')\n",
    "reca = recall_score(y_test,Yhat,average='weighted')\n",
    "print('Accuracy\\t Precision\\t Recall\\n %0.3f\\t %0.3f\\t %0.3f'%(accu,prec,reca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# si yo quisiera ver sólo un árbol\n",
    "#no se puede imprimir todo el árbol aleatorio\n",
    "from sklearn import tree\n",
    "tree.plot_tree(modelo.estimators_[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Buscar un número bueno de árboles a usar\n",
    "ntrees = np.arange(1,20,1)\n",
    "R2_s = np.zeros(len(ntrees))\n",
    "for n in range(len(ntrees)):\n",
    "    model = RandomForestClassifier(n_estimators=ntrees[n],\n",
    "                               criterion='gini',\n",
    "                               max_depth=None,\n",
    "                               min_samples_split=2,\n",
    "                               min_samples_leaf=1,\n",
    "                               max_features='auto',\n",
    "                               bootstrap=True,\n",
    "                               oob_score=False,\n",
    "                               random_state=0,\n",
    "                               verbose=0)\n",
    "    model = model.fit(X_train,y_train)\n",
    "    R2_s[n] = model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(ntrees,R2_s,c='r',label='ntrees')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Trees')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usando cross validation y grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = RandomForestClassifier(criterion='gini',\n",
    "                               min_samples_leaf=2,\n",
    "                               max_features='auto',\n",
    "                               bootstrap=True,\n",
    "                               oob_score=False,\n",
    "                               random_state=0,\n",
    "                               verbose=0)\n",
    "\n",
    "gs = GridSearchCV(model,\n",
    "                  param_grid = {'max_depth': range(1, 8),\n",
    "                                'min_samples_split': range(5, 10, 2),\n",
    "                                'n_estimators': range(2,5,1)}, \n",
    "                  cv=10,\n",
    "                  scoring='accuracy')\n",
    "\n",
    "gs.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crear modelo usando parámetros óptimos\n",
    "new_model = RandomForestClassifier(n_estimators=2,\n",
    "                               criterion='gini',\n",
    "                               max_depth=2,\n",
    "                               min_samples_split=5,\n",
    "                               min_samples_leaf=2,\n",
    "                               max_features='auto',\n",
    "                               bootstrap=True,\n",
    "                               oob_score=False,\n",
    "                               random_state=0,\n",
    "                               verbose=0)\n",
    "new_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluacion del modelo\n",
    "yhat = new_model.predict(X_test)\n",
    "accu = accuracy_score(y_test,yhat)\n",
    "prec = precision_score(y_test,yhat,average='weighted')\n",
    "reca = recall_score(y_test,yhat,average='weighted')\n",
    "print('Accuracy\\t Precision\\t Recall\\n %0.3f\\t %0.3f\\t %0.3f'%(accu,prec,reca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ventajas**\n",
    "\n",
    "- Son muy buenos generalizando\n",
    "- Protejen en contra del sobreajuste (overfitting) gracias a la construcción del bootstrapping \n",
    "- También reducen la varianza y por lo tanto mejoran la precisión del modelo\n",
    "- Funcionan muy bien con variables categóricas y variables continuas\n",
    "- No se requiere escalamiento previo de variables \n",
    "- Manejan muy bien el hecho de que haya datos nulos\n",
    "- Son modelos robustos ante valores atípicos (outliers)\n",
    "- Son algoritmos muy estables, cuando hay datos nuevos, el algoritmo no se ve muy afectado. Ya que este nuevo dato puede afectar a un árbol individual, pero es difícil que impacte a todos los árboles. \n",
    "\n",
    "**Desventajas**\n",
    "\n",
    "- Complejidad. Los bosques aleatorios crean muchos árboles y combina sus resultados. Requiere mucho poder computacional y recursos \n",
    "- Periodos de entrenamiento largos. Requieren más tiempo de entrenamiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
