{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://miro.medium.com/max/1400/1*QJZ6W-Pck_W7RlIDwUIN9Q.jpeg\" width=\"350px\" height=\"180px\" />\n",
    "\n",
    "\n",
    "# <font color= #8A0829> Laboratorio de Modelado de Datos </font>\n",
    "- <Strong> Flavio Maximiliano Herrada Avalos</Strong>\n",
    "- <Strong> Año </Strong>: 2021\n",
    "- <Strong> Email: </Strong>  <font color=\"blue\"> `flavio.herrada@iteso.mx` </font>\n",
    "___\n",
    "\n",
    "<p style=\"text-align:right;\"> Imagen recuperada de: https://miro.medium.com/max/1400/1*QJZ6W-Pck_W7RlIDwUIN9Q.jpeg</p>\n",
    "\n",
    "### <font color= #2E9AFE> Tema: Clasificación</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Características\n",
    "- Consiste en un ensamblado **secuencial** de árboles de decisión. Los árboles se agregan secuencialmente con la finalidad de aprender del resultado de árboles anteriores y corregir el error producido por los mismos, hasta que ya no se pueda corregir dicho error.\n",
    "- Utiliza el procesamiento en paralelo, poda de árboles, manejo de valores nulos, regularización para evitar el sobreajuste del modelo \n",
    "\n",
    "#### Aplicaciones\n",
    "Uno de los sectores en los que se aplican este tipo de algoritmos es el financiero.\n",
    "Algunos ejemplos de su aplicación son: segmentación de clientes, detección de fraudes, pronóstico de ventas, autenticación de clientes y análisis de comportamiento de mercados. \n",
    "\n",
    "Un área de interés es identificar clientes a quienes otorgar una tarjeta de crédito, esto es crítico para los bancos, ya que una selección incorrecta de estos clientes podría derivar en un incremento de su cartera vencida.\n",
    "\n",
    "\n",
    "#### Parámetros a optimizar\n",
    "\n",
    "- Tasa de aprendizaje (eta)\n",
    "- Profundidad del árbol\n",
    "- Gamma (para podar el árbol)\n",
    "- Lambda (regularización)\n",
    "- Min child weight\n",
    "- scale_pos_weigth\n",
    "\n",
    "#### Ventajas de XGBoost\n",
    "\n",
    "- Puede manejar grandes bases de datos con muchas variables\n",
    "- Puede manejar datos nulos\n",
    "- Resultados muy precisos\n",
    "- Rápidos de ejecutar\n",
    "\n",
    "#### Desventajas de XGBoost\n",
    "- Puede consumir muchos recursos computacionales, por lo que se recomienda determinar antes cuáles son las variables que aportarán más información al modelo\n",
    "- Se deben ajustar correctamente los parámetros del algoritmo\n",
    "- Es conveniente transformar los datos a que todos sean numéricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación\n",
    "\n",
    "### Datos\n",
    "\n",
    "Vamos a utilizar los datos de **IBM Base Samples** para predecir si un cliente va a dejar de usar los servicios de IBM. \n",
    "\n",
    "Los datos se pueden descargar de:\n",
    "https://www.kaggle.com/yeanzc/telco-customer-churn-ibm-dataset\n",
    "\n",
    "Se tienen 7043 observaciones y 33 variables\n",
    "\n",
    "- CustomerID: ID único que identifica a cada cliente.\n",
    "- Count: valor utilizado en informes para sumar el número de clientes en un conjunto determinado.\n",
    "- Country: donde vive el cliente\n",
    "- State: estado donde vive el cliente\n",
    "- Ciudad: ciudad donde vive el cliente\n",
    "- Zip Code: zip code donde vive el cliente\n",
    "- Lat Long: La latitud y longitud combinadas de la residencia principal del cliente.\n",
    "- Latitude: latitud \n",
    "- Longitude: longitud\n",
    "- Gender: género\n",
    "- Senior Citizen: Indica si el cliente es 65 o mayor: Yes, No\n",
    "- Partner: Indica si el cliente tiene un socio: Yes, No\n",
    "- Dependents: Indica si el cliente tiene algún dependiente: yes, no. (Hijos, padres, abuelos, etc). \n",
    "- Tenure Months: Indicates the total amount of months that the customer has been with the company by the end of the quarter specified above.\n",
    "- Phone Service: Indica si el cliente está suscrito al servicio de telefonía residencial con la empresa: Yes, No\n",
    "- Multiple Lines: Indica si el cliente se suscribe a múltiples líneas telefónicas con la empresa: Yes, No\n",
    "- Internet Service: Indica si el cliente se suscribe al servicio de Internet con la empresa: No, DSL, Fiber Optic, Cable.\n",
    "- Online Security: Indica si el cliente se suscribe a un servicio de seguridad online adicional proporcionado por la empresa: Yes, No\n",
    "- Online Backup: Indica si el cliente se suscribe a un servicio adicional de respaldo en línea proporcionado por la empresa: Yes, No\n",
    "- Device Protection: Indica si el cliente se suscribe a un plan adicional de protección de dispositivos para su equipo de Internet proporcionado por la empresa: Yes, No\n",
    "- Tech Support: Indica si el cliente se suscribe a un plan de soporte técnico adicional de la empresa con tiempos de espera reducidos: Yes, No\n",
    "- Streaming TV: Indica si el cliente utiliza su servicio de Internet para transmitir programación de televisión de un proveedor externo: Sí, No. La empresa no cobra una tarifa adicional por este servicio.\n",
    "- Streaming Movies: Indica si el cliente utiliza su servicio de Internet para transmitir películas de un proveedor externo: Sí, No. La empresa no cobra una tarifa adicional por este servicio.\n",
    "- Contract: Indica el tipo de contrato actual del cliente: Month-to-Month, One Year, Two Year.\n",
    "- Paperless Billing: Indica si el cliente ha elegido facturación electrónica: Yes, No\n",
    "- Payment Method: Indica cómo el cliente paga su factura: Bank Withdrawal, Credit Card, Mailed Check\n",
    "- Monthly Charge: Indica el cargo mensual total actual del cliente por todos sus servicios de la compañía\n",
    "- Total Charges: Indica los cargos totales del cliente, calculados al final del trimestre especificado anteriormente.\n",
    "- Churn Label: Yes = the customer left the company this quarter. No = the customer remained with the company. Directly related to Churn Value.\n",
    "- Churn Value: 1 = el cliente dejó la compañía este cuarto 0 = el cliente sigue con la compañía. \n",
    "- Churn Score: Un valor de 0 a 100 que se calcula utilizando la herramienta predictiva IBM SPSS Modeler. El modelo incorpora múltiples factores que se sabe que causan abandono. Cuanto más alto sea el puntaje, más probable es que el cliente abandone.\n",
    "- CLTV: Customer Lifetime Value. Valor de por vida del cliente. Un CLTV pronosticado se calcula utilizando fórmulas corporativas y datos existentes. Cuanto mayor sea el valor, más valioso será el cliente. Los clientes de alto valor deben ser monitoreados por abandono.\n",
    "- Churn reason: La razón específica de un cliente para dejar la empresa. Directamente relacionado con la categoría Churn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, balanced_accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar datos\n",
    "data = pd.read_excel('Telco_customer_churn.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vistazo de los datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpiar y procesamiento de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quitar espacio en blanco de los nombres de las columnas y reemplazar por guión bajo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La columna \"Total Charges\" parece ser una variable categórica (object) pero al hacer un vistazo \n",
    "#en los datos (data.head()) parece haber datos numéricos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convertimos la variable Total Charges a numérica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parece haber filas con espacio en blanco y por eso toma a la variable como categórica\n",
    "# Sustituimos esos valores con cero\n",
    "\n",
    "#convertimos a tipo de dato numérico\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Existen 4 variables que debemos remover\n",
    "data.drop(['Churn_Label','Churn_Reason','Churn_Score','CLTV'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminar variables que tienen muy poca varianza (que contienen muy pocos valores únicos)\n",
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quitamos CustomerID, Lat Long, count, country y state\n",
    "data.drop(['CustomerID','Lat_Long','Count','Country','State'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quitar espacio en blanco de los valores de las columnas y reemplazar por guión bajo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separar nuestras X de nuestras Y\n",
    "X = data.drop('Churn_Value', axis=1).copy()\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Churn_Value'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear variables dummy. Convertir una varialbe categórica en múltiples columnas con valores binarios\n",
    "X_nuevo = pd.get_dummies(X, columns=['City','Gender','Senior_Citizen','Partner','Dependents',\n",
    "                           'Phone_Service','Multiple_Lines','Internet_Service','Online_Security',\n",
    "                          'Online_Backup','Device_Protection','Tech_Support','Streaming_TV',\n",
    "                          'Streaming_Movies','Contract','Paperless_Billing','Payment_Method'])\n",
    "X_nuevo.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viendo si nuestra variable a predecir tiene datos imbalanceados\n",
    "sum(y)/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Construcción del modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividir los datos en train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_nuevo, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_train)/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construir el xgboost\n",
    "#inicializar objeto de clasificación\n",
    "modelo = xgb.XGBClassifier(objective='', missing=1, seed=42)\n",
    "#Entrenar modelo\n",
    "modelo.fit(X_train, y_train, verbose=True,\n",
    "          early_stopping_rounds=10, #parar de construir más árboles si no mejora la situación de los residuales\n",
    "          eval_metric='aucpr',\n",
    "          eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ver cómo funciona el modelo entrenado con los datos de prueba\n",
    "plot_confusion_matrix(modelo, X_test, y_test, values_format='d', display_labels=[\"No se fue\",\"Se fue\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la matriz de confusión vemos que de 1294 personas que no se fueron, 1148 (88%) fueron clasificados correctamente. \n",
    "\n",
    "Y de los 467 personas que sí se fueron, 255 (54%) fueron clasificados correctamente. \n",
    "\n",
    "Entonces el modelo de XGBoost no fue tan bueno. Parte del problema es que los datos están imbalanceados. \n",
    "\n",
    "Ya que el hecho de que se vaya la gente y deje los servicios de IBM cuesta dinero, queremos capturar más la información de las personas que se fueron. La buena noticia es que XGBoost tiene un parámetro, \n",
    "*scale_pos_weight*, que ayuda con datos imbalanceados. \n",
    "\n",
    "Utilicemos **cross-validation** para optimizar los parámetros. \n",
    "\n",
    "#### Cross validation y GridSearch para optimizar los hiper-parámetros\n",
    "\n",
    "XGBoost tiene muchísimos hiper-parámetros a ajustar ya sean:\n",
    "- max_depth \n",
    "- learning_rate (eta)\n",
    "- gamma\n",
    "- reg_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#como es bien tardado el proceso del ajuste de hiperparámetros, en lugar de optimizar todo\n",
    "#de una vez, optimicé parámetros por secciones para hacerlo más rápido\n",
    "\n",
    "#Ronda 1\n",
    "#param_grid={\n",
    "#    'max_depth':[3,4,5],\n",
    "#    'learning_rate':[0.1,0.01,0.05],\n",
    "#    'gamma':[0, 0.25,1],\n",
    "#    'reg_lambda':[0,1,10],\n",
    "#    'scale_pos_weight':[1,3,5]\n",
    "#}\n",
    "\n",
    "#Ronda 2\n",
    "param_grid={\n",
    "    'max_depth':[4],\n",
    "    'learning_rate':[0.1,0.5,1],\n",
    "    'gamma':[0.25],\n",
    "    'reg_lambda':[10,20,100],\n",
    "    'scale_pos_weight':[3]\n",
    "}\n",
    "\n",
    "optimal_params = GridSearchCV(\n",
    "                            estimator=xgb.XGBClassifier(objective='binary:logistic',\n",
    "                            seed=42,\n",
    "                            subsample=0.9,\n",
    "                            colsample_bytree=0.5),\n",
    "                            param_grid=param_grid,\n",
    "                            scoring='roc_auc',\n",
    "                            verbose=0,\n",
    "                            n_jobs=10,\n",
    "                            cv=3)\n",
    "\n",
    "optimal_params.fit(X_train, y_train,\n",
    "                  early_stopping_rounds=10,\n",
    "                  eval_metric='auc',\n",
    "                  eval_set=[(X_test, y_test)],\n",
    "                  verbose=False)\n",
    "optimal_params.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'gamma': 0.25,\n",
    " 'learning_rate': 0.1,\n",
    " 'max_depth': 4,\n",
    " 'reg_lambda': 10,\n",
    " 'scale_pos_weight': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construir y evaluar el XGBoost con los hiperparámetros óptimos\n",
    "modelo = xgb.XGBClassifier(objective='binary:logistic',\n",
    "                            seed=42,\n",
    "                           gamma=0.25,\n",
    "                           learn_rate=0.1,\n",
    "                           max_depth=4,\n",
    "                           reg_lambda=10,\n",
    "                           scale_pos_weight=3,\n",
    "                            subsample=0.9,\n",
    "                            colsample_bytree=0.5)\n",
    "\n",
    "modelo.fit(X_train, y_train,\n",
    "                  early_stopping_rounds=10,\n",
    "                  eval_metric='auc',\n",
    "                  eval_set=[(X_test, y_test)],\n",
    "                  verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ver cómo funciona el modelo entrenado con los datos de prueba\n",
    "plot_confusion_matrix(modelo, X_test, y_test, values_format='d', display_labels=[\"No se fue\",\"Se fue\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la matriz de confusión vemos que de 1294 personas que no se fueron, 933 (72%) fueron clasificados correctamente. \n",
    "\n",
    "Y de los 467 personas que sí se fueron, 387 (82%) fueron clasificados correctamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Un poco de bibliografía...\n",
    "https://www.kaggle.com/prashant111/a-guide-on-xgboost-hyperparameters-tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
