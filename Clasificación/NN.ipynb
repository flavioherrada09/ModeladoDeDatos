{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://bernardmarr.com/img/What%20is%20an%20Artificial%20Neural%20Networks.jpg\" width=\"350px\" height=\"180px\" />\n",
    "\n",
    "\n",
    "# <font color= #8A0829> Laboratorio de Modelado de Datos </font>\n",
    "#### <font color= #2E9AFE> `Martes y Viernes (Videoconferencia) de 13:00 - 15:00 hrs`</font>\n",
    "- <Strong> Sara Eugenia Rodríguez </Strong>\n",
    "- <Strong> Año </Strong>: 2022\n",
    "- <Strong> Email: </Strong>  <font color=\"blue\"> `cd682324@iteso.mx` </font>\n",
    "___\n",
    "\n",
    "<p style=\"text-align:right;\"> Imagen recuperada de: https://bernardmarr.com/img/What%20is%20an%20Artificial%20Neural%20Networks.jpg</p>\n",
    "\n",
    "### <font color= #2E9AFE> Tema: Redes Neuronales para Clasificación</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Las redes neuronales para clasificación toman como salida valores discretos, generalmente valores binarios (0, 1)\n",
    "- Aplicar con éxito en la red neuronal a un problema de clasificación requiere que los valores de la red estén limitados en un rango de 0 y 1.\n",
    "- Una transformación no lineal es incluída en el modelo de red neuronal. Usualmente esta transformación es una función sigmoidal. \n",
    "\n",
    "**Entonces... ¿qué pasaría si tengo una red neuronal con sólo una capa, donde la función de activación es sigmoidal? sería lo mismo que aplicar una regresión logística**\n",
    "\n",
    "Red neuronal con una capa con función de activación sigmoidal = Regresión logística\n",
    "\n",
    "**Modelo matemático**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= #66CC00>$$\\nu^{1} = w_{0}^{1}+w^{1}$$</font>\n",
    "<font color= #66CC00>$$y^{1} = \\varphi(\\nu^{1})$$</font>\n",
    "<font color= #009900>$$\\nu^{2} = w_{0}^{2}+w^{2}y_{1}$$</font>\n",
    "<font color= #009900>$$y^{2} = \\varphi(\\nu^{2})$$</font>\n",
    "<font color= #3399FF>$$\\nu^{3} = w_{0}^{3}+w^{3}y_{2}$$</font>\n",
    "<font color= #3399FF>$$y^{3} = \\varphi(\\nu^{3})$$</font>\n",
    "\n",
    "Para un problema de clasificación multiclase, el número de salidas aumenta en función del número de clases a clasificar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo para salida binaria**\n",
    "\n",
    "Queremos predecir si una persona va a tener diabetes o no (Outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerías\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "desc = data.describe()\n",
    "info = data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seleccionar datos para train y test\n",
    "X = data.iloc[:,0:8]\n",
    "Y = np.ravel(data['Outcome'])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escalar datos\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6284 - accuracy: 0.6629\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6201 - accuracy: 0.6760\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6118 - accuracy: 0.6816\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6043 - accuracy: 0.6909\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5972 - accuracy: 0.6965\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5905 - accuracy: 0.7076\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.7169\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5783 - accuracy: 0.7207\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5726 - accuracy: 0.7225\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.7263\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5622 - accuracy: 0.7318\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.7412\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5526 - accuracy: 0.7430\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.7467\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5440 - accuracy: 0.7449\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.7542\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5363 - accuracy: 0.7598\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7598\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7579\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7616\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.7654\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7709\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5179 - accuracy: 0.7728\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7747\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7728\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7747\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.7784\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7765\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7765\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5015 - accuracy: 0.7747\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.7728\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.7709\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.7709\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.7709\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.7709\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.7747\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7728\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.7709\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7728\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.7709\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7691\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.7691\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7709\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7728\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7728\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.7747\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4778 - accuracy: 0.7765\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4768 - accuracy: 0.7784\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.7784\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7803\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7784\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7784\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7765\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7803\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7821\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7840\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7840\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.7840\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7821\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7840\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7821\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7821\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7821\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7803\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.7803\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7803\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7821\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7821\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7840\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7840\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7821\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7821\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7803\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7821\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7803\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7821\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7803\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7803\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7803\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7803\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7803\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7803\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7803\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7803\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7840\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7821\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7821\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7821\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7821\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7840\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4556 - accuracy: 0.7840\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7840\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.7840\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7858\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.7858\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7877\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7877\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.7877\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7877\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.7877\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.7877\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.7896\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7877\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.7896\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7858\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7840\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.7858\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.7858\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7840\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7821\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7840\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7858\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7840\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7840\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7840\n",
      "Epoch 116/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7821\n",
      "Epoch 117/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.7858\n",
      "Epoch 118/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7821\n",
      "Epoch 119/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7803\n",
      "Epoch 120/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7803\n",
      "Epoch 121/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7803\n",
      "Epoch 122/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4504 - accuracy: 0.7803\n",
      "Epoch 123/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7821\n",
      "Epoch 124/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.7821\n",
      "Epoch 125/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7840\n",
      "Epoch 126/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7821\n",
      "Epoch 127/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7821\n",
      "Epoch 128/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7821\n",
      "Epoch 129/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.7840\n",
      "Epoch 130/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7821\n",
      "Epoch 131/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7821\n",
      "Epoch 132/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7803\n",
      "Epoch 133/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7821\n",
      "Epoch 134/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7821\n",
      "Epoch 135/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7803\n",
      "Epoch 136/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7821\n",
      "Epoch 137/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7803\n",
      "Epoch 138/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7803\n",
      "Epoch 139/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7803\n",
      "Epoch 140/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7821\n",
      "Epoch 141/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7803\n",
      "Epoch 142/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.7803\n",
      "Epoch 143/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7803\n",
      "Epoch 144/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7803\n",
      "Epoch 145/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.7803\n",
      "Epoch 146/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7803\n",
      "Epoch 147/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.7803\n",
      "Epoch 148/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7821\n",
      "Epoch 149/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7803\n",
      "Epoch 150/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7803\n",
      "Epoch 151/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7784\n",
      "Epoch 152/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.7784\n",
      "Epoch 153/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7784\n",
      "Epoch 154/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7784\n",
      "Epoch 155/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.7784\n",
      "Epoch 156/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7784\n",
      "Epoch 157/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7784\n",
      "Epoch 158/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4468 - accuracy: 0.7784\n",
      "Epoch 159/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4468 - accuracy: 0.7784\n",
      "Epoch 160/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7784\n",
      "Epoch 161/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7784\n",
      "Epoch 162/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7784\n",
      "Epoch 163/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.7784\n",
      "Epoch 164/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7784\n",
      "Epoch 165/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7803\n",
      "Epoch 166/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7803\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7803\n",
      "Epoch 168/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7803\n",
      "Epoch 169/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7803\n",
      "Epoch 170/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7803\n",
      "Epoch 171/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7803\n",
      "Epoch 172/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7803\n",
      "Epoch 173/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7803\n",
      "Epoch 174/200\n",
      "6/6 [==============================] - 0s 949us/step - loss: 0.4458 - accuracy: 0.7803\n",
      "Epoch 175/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7803\n",
      "Epoch 176/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7803\n",
      "Epoch 177/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7803\n",
      "Epoch 178/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7803\n",
      "Epoch 179/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7803\n",
      "Epoch 180/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7803\n",
      "Epoch 181/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7803\n",
      "Epoch 182/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7803\n",
      "Epoch 183/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.7803\n",
      "Epoch 184/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7803\n",
      "Epoch 185/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7803\n",
      "Epoch 186/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7803\n",
      "Epoch 187/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7784\n",
      "Epoch 188/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7803\n",
      "Epoch 189/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7803\n",
      "Epoch 190/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4449 - accuracy: 0.7803\n",
      "Epoch 191/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7803\n",
      "Epoch 192/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7803\n",
      "Epoch 193/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7803\n",
      "Epoch 194/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7803\n",
      "Epoch 195/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7803\n",
      "Epoch 196/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7803\n",
      "Epoch 197/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7803\n",
      "Epoch 198/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7803\n",
      "Epoch 199/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7803\n",
      "Epoch 200/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.7803\n"
     ]
    }
   ],
   "source": [
    "#Construir red neuronal\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Estructura de la red neuronal\n",
    "model = Sequential()\n",
    "model.add(Dense(8, activation='tanh', input_shape=(8,))) #se puede cambiar la función de activación\n",
    "model.add(Dense(1, activation='sigmoid')) #La capa de salida debe ser \"\" para problemas binomiales (0 y 1)\n",
    "\n",
    "# Configuración del optimizador\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entrenamiento de la red neuronal\n",
    "model_history=model.fit(X_train, Y_train,epochs=200, batch_size=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text(0.5, 0, 'Epochs'), Text(0, 0.5, 'Accuracy function'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ver el performance del modelo en el entrenamiento\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.subplot(122)\n",
    "plt.plot(model_history.history['accuracy'])\n",
    "plt.xlabel('Epochs'),plt.ylabel('Accuracy function')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#Usar el modelo para predecir\n",
    "Y_pred = model.predict(X_test)\n",
    "Y_prob = (model.predict(X_test) > 0.5).astype(\"int32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26888117],\n",
       "       [0.13939308],\n",
       "       [0.08987923],\n",
       "       [0.28588742],\n",
       "       [0.54809153],\n",
       "       [0.43042699],\n",
       "       [0.02122162],\n",
       "       [0.67798895],\n",
       "       [0.6524538 ],\n",
       "       [0.645802  ],\n",
       "       [0.24493134],\n",
       "       [0.78283304],\n",
       "       [0.4552912 ],\n",
       "       [0.30534527],\n",
       "       [0.08371574],\n",
       "       [0.4017931 ],\n",
       "       [0.12104912],\n",
       "       [0.04829602],\n",
       "       [0.82511926],\n",
       "       [0.64075494],\n",
       "       [0.2605629 ],\n",
       "       [0.05867547],\n",
       "       [0.48559895],\n",
       "       [0.06526577],\n",
       "       [0.5667101 ],\n",
       "       [0.8847112 ],\n",
       "       [0.08694103],\n",
       "       [0.03057555],\n",
       "       [0.25435993],\n",
       "       [0.09637661],\n",
       "       [0.9103619 ],\n",
       "       [0.72752035],\n",
       "       [0.848151  ],\n",
       "       [0.8599205 ],\n",
       "       [0.5865841 ],\n",
       "       [0.6999458 ],\n",
       "       [0.7908563 ],\n",
       "       [0.24756613],\n",
       "       [0.44529888],\n",
       "       [0.7067827 ],\n",
       "       [0.04624542],\n",
       "       [0.65399885],\n",
       "       [0.5899608 ],\n",
       "       [0.43880668],\n",
       "       [0.0413006 ],\n",
       "       [0.52983654],\n",
       "       [0.7533656 ],\n",
       "       [0.18257885],\n",
       "       [0.48680437],\n",
       "       [0.94409287],\n",
       "       [0.0356887 ],\n",
       "       [0.75980884],\n",
       "       [0.7312887 ],\n",
       "       [0.29912952],\n",
       "       [0.12252728],\n",
       "       [0.03107391],\n",
       "       [0.6703547 ],\n",
       "       [0.02464772],\n",
       "       [0.4509414 ],\n",
       "       [0.79745084],\n",
       "       [0.77606523],\n",
       "       [0.34558547],\n",
       "       [0.24687581],\n",
       "       [0.2604803 ],\n",
       "       [0.06950976],\n",
       "       [0.6383338 ],\n",
       "       [0.03598536],\n",
       "       [0.71087736],\n",
       "       [0.07475959],\n",
       "       [0.7678021 ],\n",
       "       [0.7927063 ],\n",
       "       [0.05421325],\n",
       "       [0.2507091 ],\n",
       "       [0.09101711],\n",
       "       [0.08167477],\n",
       "       [0.5978331 ],\n",
       "       [0.19972692],\n",
       "       [0.10944702],\n",
       "       [0.12244566],\n",
       "       [0.23124382],\n",
       "       [0.74993664],\n",
       "       [0.10578346],\n",
       "       [0.05033902],\n",
       "       [0.3794902 ],\n",
       "       [0.27078065],\n",
       "       [0.89162165],\n",
       "       [0.86623746],\n",
       "       [0.32576838],\n",
       "       [0.08789979],\n",
       "       [0.06620761],\n",
       "       [0.05579945],\n",
       "       [0.23183075],\n",
       "       [0.01957007],\n",
       "       [0.4811379 ],\n",
       "       [0.5548623 ],\n",
       "       [0.7215395 ],\n",
       "       [0.43832335],\n",
       "       [0.09230813],\n",
       "       [0.53343976],\n",
       "       [0.10363458],\n",
       "       [0.71004176],\n",
       "       [0.05426444],\n",
       "       [0.79272044],\n",
       "       [0.57509613],\n",
       "       [0.6543126 ],\n",
       "       [0.20776847],\n",
       "       [0.29048538],\n",
       "       [0.7383877 ],\n",
       "       [0.19322613],\n",
       "       [0.5619541 ],\n",
       "       [0.07193378],\n",
       "       [0.34970784],\n",
       "       [0.05888466],\n",
       "       [0.7814105 ],\n",
       "       [0.1451739 ],\n",
       "       [0.3097022 ],\n",
       "       [0.79713744],\n",
       "       [0.21514113],\n",
       "       [0.08320513],\n",
       "       [0.52068913],\n",
       "       [0.0523519 ],\n",
       "       [0.24713352],\n",
       "       [0.20050587],\n",
       "       [0.19020708],\n",
       "       [0.26457635],\n",
       "       [0.38262686],\n",
       "       [0.07157339],\n",
       "       [0.86229336],\n",
       "       [0.8414234 ],\n",
       "       [0.70909446],\n",
       "       [0.5923402 ],\n",
       "       [0.885796  ],\n",
       "       [0.15977624],\n",
       "       [0.49688065],\n",
       "       [0.75135076],\n",
       "       [0.09671256],\n",
       "       [0.1903004 ],\n",
       "       [0.8552921 ],\n",
       "       [0.83383554],\n",
       "       [0.01950764],\n",
       "       [0.07047242],\n",
       "       [0.03708845],\n",
       "       [0.19220527],\n",
       "       [0.42678517],\n",
       "       [0.10609049],\n",
       "       [0.3041214 ],\n",
       "       [0.21540295],\n",
       "       [0.02402832],\n",
       "       [0.4636345 ],\n",
       "       [0.81400365],\n",
       "       [0.15950434],\n",
       "       [0.49590978],\n",
       "       [0.30379996],\n",
       "       [0.16956575],\n",
       "       [0.03083224],\n",
       "       [0.52160203],\n",
       "       [0.32313097],\n",
       "       [0.6000227 ],\n",
       "       [0.61098814],\n",
       "       [0.14820468],\n",
       "       [0.5205438 ],\n",
       "       [0.73493356],\n",
       "       [0.15610933],\n",
       "       [0.02767332],\n",
       "       [0.09377477],\n",
       "       [0.8874111 ],\n",
       "       [0.03644519],\n",
       "       [0.29730114],\n",
       "       [0.8512198 ],\n",
       "       [0.55361074],\n",
       "       [0.7162545 ],\n",
       "       [0.18005562],\n",
       "       [0.36950764],\n",
       "       [0.78138894],\n",
       "       [0.6620979 ],\n",
       "       [0.09852944],\n",
       "       [0.28027046],\n",
       "       [0.26921237],\n",
       "       [0.21349771],\n",
       "       [0.35343632],\n",
       "       [0.5624866 ],\n",
       "       [0.580176  ],\n",
       "       [0.4236449 ],\n",
       "       [0.8041518 ],\n",
       "       [0.7177739 ],\n",
       "       [0.08629738],\n",
       "       [0.05295856],\n",
       "       [0.09966903],\n",
       "       [0.81093836],\n",
       "       [0.40800482],\n",
       "       [0.05628465],\n",
       "       [0.06912304],\n",
       "       [0.8207488 ],\n",
       "       [0.18909001],\n",
       "       [0.16235986],\n",
       "       [0.05336932],\n",
       "       [0.05688421],\n",
       "       [0.04731673],\n",
       "       [0.22334114],\n",
       "       [0.7801261 ],\n",
       "       [0.15241812],\n",
       "       [0.09136477],\n",
       "       [0.43661502],\n",
       "       [0.37432995],\n",
       "       [0.7291137 ],\n",
       "       [0.09585127],\n",
       "       [0.07969367],\n",
       "       [0.23910831],\n",
       "       [0.8819347 ],\n",
       "       [0.6426361 ],\n",
       "       [0.250582  ],\n",
       "       [0.1697823 ],\n",
       "       [0.11458142],\n",
       "       [0.1379654 ],\n",
       "       [0.668727  ],\n",
       "       [0.1031286 ],\n",
       "       [0.6787793 ],\n",
       "       [0.3851818 ],\n",
       "       [0.35801363],\n",
       "       [0.8711161 ],\n",
       "       [0.69105196],\n",
       "       [0.09435154],\n",
       "       [0.06651598],\n",
       "       [0.11802096],\n",
       "       [0.06007053],\n",
       "       [0.6882991 ],\n",
       "       [0.31240898],\n",
       "       [0.2841013 ],\n",
       "       [0.29697758],\n",
       "       [0.18625814],\n",
       "       [0.13062957]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7403\n",
      "[0.506792426109314, 0.7402597665786743]\n"
     ]
    }
   ],
   "source": [
    "#Evaluar modelo\n",
    "score = model.evaluate(X_test, Y_test,verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      " \t Accu \t Prec \t Reca\n",
      " Train \t 0.780 \t 0.713 \t 0.622\n",
      "  Test \t 0.740 \t 0.622 \t 0.637\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,f1_score)\n",
    "accu_train = accuracy_score(Y_train,(model.predict(X_train) > 0.5).astype(\"int32\"))\n",
    "prec_train = precision_score(Y_train,(model.predict(X_train) > 0.5).astype(\"int32\"))\n",
    "reca_train = recall_score(Y_train,(model.predict(X_train) > 0.5).astype(\"int32\"))\n",
    "\n",
    "\n",
    "accu_test = accuracy_score(Y_test,(model.predict(X_test) > 0.5).astype(\"int32\"))\n",
    "prec_test = precision_score(Y_test,(model.predict(X_test) > 0.5).astype(\"int32\"))\n",
    "reca_test = recall_score(Y_test,(model.predict(X_test) > 0.5).astype(\"int32\"))\n",
    "\n",
    "print(' \\t Accu \\t Prec \\t Reca\\n Train \\t %0.3f \\t %0.3f \\t %0.3f\\n  Test \\t %0.3f \\t %0.3f \\t %0.3f'%(accu_train,prec_train,reca_train,accu_test,prec_test,reca_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \t Accu \t Prec \t Reca\n",
      " Train \t 0.782 \t 0.741 \t 0.580\n",
      "  Test \t 0.736 \t 0.617 \t 0.625\n"
     ]
    }
   ],
   "source": [
    "#Comparar contra Regresión logística\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_log = LogisticRegression()\n",
    "model_log.fit(X_train,Y_train)\n",
    "Yhat = model_log.predict(X_train)\n",
    "\n",
    "accu_train = accuracy_score(Y_train,Yhat)\n",
    "prec_train = precision_score(Y_train,Yhat)\n",
    "reca_train = recall_score(Y_train,Yhat)\n",
    "\n",
    "Yhat = model_log.predict(X_test)\n",
    "accu_test = accuracy_score(Y_test,Yhat)\n",
    "prec_test = precision_score(Y_test,Yhat)\n",
    "reca_test = recall_score(Y_test,Yhat)\n",
    "\n",
    "print(' \\t Accu \\t Prec \\t Reca\\n Train \\t %0.3f \\t %0.3f \\t %0.3f\\n  Test \\t %0.3f \\t %0.3f \\t %0.3f'%(accu_train,prec_train,reca_train,accu_test,prec_test,reca_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo Multiclase**\n",
    "\n",
    "- Aunque las salidas de la red neuronal están limitadas a un rango de valores entre 0 y 1, no se garantiza que la suma de estos sea igual a 1\n",
    "- Transformar las salidas para que puedan ser usadas como probabilidades ayuda mucho a la interpretabilidad de las predicciones\n",
    "- Transformación Softmax\n",
    "\n",
    "$$\\hat{p}_{l,i}^{*} = \\frac{e^{\\hat{y}_{l,i}}}{\\sum{e^{\\hat{y}_{l,i}}}}$$\n",
    "\n",
    "- $\\hat{y}_{1}=0.25$, $\\hat{y}_{2}=0.76$, $\\hat{y}_{3}=0.1$\n",
    "\n",
    "- $\\hat{p}_{1}=0.3099$, $\\hat{p}_{2}=0.4717$, $\\hat{p}_{3}=0.2184$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerías\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import SGD, Adam\n",
    "#from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Datos\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "Y #tres tipos de flores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos la variable target a dummies\n",
    "dummy_y = np_utils.to_categorical(Y).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividimos los datos en test y train\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dummy_y,\n",
    "                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09090\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 517ms/step - loss: 1.8527 - accuracy: 0.3250 - val_loss: 3.4915 - val_accuracy: 0.3000\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 2.9494 - accuracy: 0.3500 - val_loss: 0.9021 - val_accuracy: 0.3667\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.9401 - accuracy: 0.3667 - val_loss: 0.8724 - val_accuracy: 0.7000\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.8910 - accuracy: 0.6583 - val_loss: 0.7913 - val_accuracy: 0.7000\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.8186 - accuracy: 0.6583 - val_loss: 0.7254 - val_accuracy: 0.7000\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.7457 - accuracy: 0.6667 - val_loss: 0.6725 - val_accuracy: 0.7333\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6834 - accuracy: 0.7000 - val_loss: 0.6271 - val_accuracy: 0.7667\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6359 - accuracy: 0.7333 - val_loss: 0.5895 - val_accuracy: 0.7000\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6063 - accuracy: 0.6667 - val_loss: 0.5596 - val_accuracy: 0.7333\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5740 - accuracy: 0.7250 - val_loss: 0.5464 - val_accuracy: 0.9333\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5477 - accuracy: 0.9500 - val_loss: 0.5124 - val_accuracy: 0.8000\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5204 - accuracy: 0.7833 - val_loss: 0.4907 - val_accuracy: 0.7667\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5034 - accuracy: 0.7333 - val_loss: 0.4746 - val_accuracy: 0.8000\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4863 - accuracy: 0.7417 - val_loss: 0.4609 - val_accuracy: 0.8000\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4723 - accuracy: 0.7833 - val_loss: 0.4563 - val_accuracy: 0.9000\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4630 - accuracy: 0.9333 - val_loss: 0.4424 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4489 - accuracy: 0.8917 - val_loss: 0.4425 - val_accuracy: 0.7333\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4626 - accuracy: 0.6917 - val_loss: 0.4349 - val_accuracy: 0.9667\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4390 - accuracy: 0.9500 - val_loss: 0.4812 - val_accuracy: 0.7000\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4709 - accuracy: 0.7417 - val_loss: 0.4062 - val_accuracy: 0.8000\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4159 - accuracy: 0.8667 - val_loss: 0.4046 - val_accuracy: 0.8000\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4205 - accuracy: 0.7667 - val_loss: 0.3925 - val_accuracy: 0.8000\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4010 - accuracy: 0.8833 - val_loss: 0.3854 - val_accuracy: 0.8000\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.3940 - accuracy: 0.8833 - val_loss: 0.3794 - val_accuracy: 0.8667\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.3866 - accuracy: 0.9333 - val_loss: 0.3721 - val_accuracy: 0.8000\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.3814 - accuracy: 0.8833 - val_loss: 0.3706 - val_accuracy: 0.9667\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3762 - accuracy: 0.9583 - val_loss: 0.3608 - val_accuracy: 0.9000\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.3624 - accuracy: 0.9583 - val_loss: 0.3940 - val_accuracy: 0.7667\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4075 - accuracy: 0.7167 - val_loss: 0.3486 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3549 - accuracy: 0.9000 - val_loss: 0.3513 - val_accuracy: 0.9667\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3513 - accuracy: 0.9667 - val_loss: 0.3516 - val_accuracy: 0.8000\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.3599 - accuracy: 0.8583 - val_loss: 0.3348 - val_accuracy: 0.8000\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3359 - accuracy: 0.9167 - val_loss: 0.3837 - val_accuracy: 0.8667\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3765 - accuracy: 0.9000 - val_loss: 0.3273 - val_accuracy: 0.8000\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3380 - accuracy: 0.8833 - val_loss: 0.3216 - val_accuracy: 0.8667\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3250 - accuracy: 0.9167 - val_loss: 0.3443 - val_accuracy: 0.9000\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3397 - accuracy: 0.9333 - val_loss: 0.3090 - val_accuracy: 0.9667\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3104 - accuracy: 0.9667 - val_loss: 0.3152 - val_accuracy: 0.8000\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.3178 - accuracy: 0.8917 - val_loss: 0.3131 - val_accuracy: 0.9667\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3250 - accuracy: 0.9417 - val_loss: 0.3269 - val_accuracy: 0.8000\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3379 - accuracy: 0.8417 - val_loss: 0.2933 - val_accuracy: 0.8667\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.2920 - accuracy: 0.9250 - val_loss: 0.4085 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4017 - accuracy: 0.8417 - val_loss: 0.3608 - val_accuracy: 0.8000\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.3528 - accuracy: 0.7917 - val_loss: 0.3417 - val_accuracy: 0.8667\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3384 - accuracy: 0.8917 - val_loss: 0.2866 - val_accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.2842 - accuracy: 0.9583 - val_loss: 0.3295 - val_accuracy: 0.8000\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3198 - accuracy: 0.8750 - val_loss: 0.3317 - val_accuracy: 0.8667\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3218 - accuracy: 0.9083 - val_loss: 0.2740 - val_accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.2742 - accuracy: 0.9500 - val_loss: 0.2632 - val_accuracy: 0.9667\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.2684 - accuracy: 0.9667 - val_loss: 0.2613 - val_accuracy: 0.9667\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.2616 - accuracy: 0.9417 - val_loss: 0.3035 - val_accuracy: 0.8000\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.2929 - accuracy: 0.8917 - val_loss: 0.3475 - val_accuracy: 0.8667\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.3381 - accuracy: 0.9083 - val_loss: 0.2532 - val_accuracy: 0.9667\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.2595 - accuracy: 0.9333 - val_loss: 0.2533 - val_accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.2589 - accuracy: 0.9583 - val_loss: 0.2454 - val_accuracy: 0.9667\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.2533 - accuracy: 0.9583 - val_loss: 0.2408 - val_accuracy: 0.9667\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.2457 - accuracy: 0.9583 - val_loss: 0.2390 - val_accuracy: 0.9667\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.2396 - accuracy: 0.9500 - val_loss: 0.2432 - val_accuracy: 0.9667\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 57ms/step - loss: 0.2379 - accuracy: 0.9667 - val_loss: 0.2688 - val_accuracy: 0.9000\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.2583 - accuracy: 0.9583 - val_loss: 0.2450 - val_accuracy: 0.9667\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.2437 - accuracy: 0.9417 - val_loss: 0.2325 - val_accuracy: 0.9667\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.2361 - accuracy: 0.9667 - val_loss: 0.2320 - val_accuracy: 0.9667\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.2315 - accuracy: 0.9500 - val_loss: 0.2255 - val_accuracy: 0.9667\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.2319 - accuracy: 0.9667 - val_loss: 0.2241 - val_accuracy: 0.9667\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.2231 - accuracy: 0.9667 - val_loss: 0.2244 - val_accuracy: 0.9667\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.2253 - accuracy: 0.9583 - val_loss: 0.2174 - val_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.2158 - accuracy: 0.9667 - val_loss: 0.2183 - val_accuracy: 0.9667\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.2155 - accuracy: 0.9583 - val_loss: 0.2356 - val_accuracy: 0.9333\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.2329 - accuracy: 0.9583 - val_loss: 0.3090 - val_accuracy: 0.8000\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3078 - accuracy: 0.8583 - val_loss: 0.2363 - val_accuracy: 0.9333\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.2657 - accuracy: 0.9083 - val_loss: 0.2372 - val_accuracy: 0.9000\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.2656 - accuracy: 0.9250 - val_loss: 0.2329 - val_accuracy: 0.9667\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.2499 - accuracy: 0.9417 - val_loss: 0.2488 - val_accuracy: 0.9333\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.2503 - accuracy: 0.9500 - val_loss: 0.2489 - val_accuracy: 0.8333\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.2518 - accuracy: 0.9167 - val_loss: 0.2137 - val_accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.2070 - accuracy: 0.9667 - val_loss: 0.2019 - val_accuracy: 0.9667\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.1974 - accuracy: 0.9667 - val_loss: 0.2013 - val_accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.2012 - accuracy: 0.9667 - val_loss: 0.2008 - val_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.2033 - accuracy: 0.9583 - val_loss: 0.1944 - val_accuracy: 0.9667\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.2007 - accuracy: 0.9500 - val_loss: 0.2475 - val_accuracy: 0.9000\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.2385 - accuracy: 0.9333 - val_loss: 0.2047 - val_accuracy: 0.9667\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.2093 - accuracy: 0.9500 - val_loss: 0.2141 - val_accuracy: 0.9333\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.2138 - accuracy: 0.9583 - val_loss: 0.2135 - val_accuracy: 0.9333\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.2037 - accuracy: 0.9667 - val_loss: 0.2425 - val_accuracy: 0.8000\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.2269 - accuracy: 0.9167 - val_loss: 0.2645 - val_accuracy: 0.9000\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.2578 - accuracy: 0.9083 - val_loss: 0.2100 - val_accuracy: 0.9667\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.2571 - accuracy: 0.9250 - val_loss: 0.2780 - val_accuracy: 0.8667\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.3236 - accuracy: 0.8500 - val_loss: 0.2424 - val_accuracy: 0.8000\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3272 - accuracy: 0.8750 - val_loss: 0.2102 - val_accuracy: 0.9667\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.2311 - accuracy: 0.9250 - val_loss: 0.4391 - val_accuracy: 0.6667\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4255 - accuracy: 0.7167 - val_loss: 0.2353 - val_accuracy: 0.8333\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.2293 - accuracy: 0.9167 - val_loss: 0.1761 - val_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.1771 - accuracy: 0.9667 - val_loss: 0.1742 - val_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.1761 - accuracy: 0.9667 - val_loss: 0.1746 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.1750 - accuracy: 0.9750 - val_loss: 0.1732 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.1726 - accuracy: 0.9667 - val_loss: 0.1752 - val_accuracy: 0.9667\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.1756 - accuracy: 0.9667 - val_loss: 0.2349 - val_accuracy: 0.9000\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.2314 - accuracy: 0.9417 - val_loss: 0.1780 - val_accuracy: 0.9667\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1912 - accuracy: 0.9667 - val_loss: 0.1670 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.1691 - accuracy: 0.9667 - val_loss: 0.2225 - val_accuracy: 0.8667\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.2099 - accuracy: 0.9417 - val_loss: 0.2399 - val_accuracy: 0.8000\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.2402 - accuracy: 0.9000 - val_loss: 0.1854 - val_accuracy: 0.9667\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.1812 - accuracy: 0.9583 - val_loss: 0.1776 - val_accuracy: 0.9667\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.1752 - accuracy: 0.9667 - val_loss: 0.1790 - val_accuracy: 0.9667\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.1844 - accuracy: 0.9583 - val_loss: 0.1782 - val_accuracy: 0.9667\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1858 - accuracy: 0.9500 - val_loss: 0.1648 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.1733 - accuracy: 0.9583 - val_loss: 0.1842 - val_accuracy: 0.9667\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.1886 - accuracy: 0.9417 - val_loss: 0.1563 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.1623 - accuracy: 0.9667 - val_loss: 0.1596 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.1624 - accuracy: 0.9750 - val_loss: 0.1578 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.1580 - accuracy: 0.9750 - val_loss: 0.1659 - val_accuracy: 0.9667\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.1661 - accuracy: 0.9667 - val_loss: 0.1562 - val_accuracy: 0.9667\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.1583 - accuracy: 0.9667 - val_loss: 0.1541 - val_accuracy: 0.9667\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.1570 - accuracy: 0.9583 - val_loss: 0.1530 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1623 - accuracy: 0.9667 - val_loss: 0.1646 - val_accuracy: 0.9667\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.1673 - accuracy: 0.9667 - val_loss: 0.1608 - val_accuracy: 0.9667\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 51ms/step - loss: 0.1577 - accuracy: 0.9667 - val_loss: 0.1728 - val_accuracy: 0.9333\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.1688 - accuracy: 0.9667 - val_loss: 0.1783 - val_accuracy: 0.9667\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.1784 - accuracy: 0.9583 - val_loss: 0.1517 - val_accuracy: 0.9667\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.1490 - accuracy: 0.9667 - val_loss: 0.2117 - val_accuracy: 0.9000\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.2136 - accuracy: 0.9417 - val_loss: 0.1526 - val_accuracy: 0.9667\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.1577 - accuracy: 0.9667 - val_loss: 0.1463 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.1513 - accuracy: 0.9833 - val_loss: 0.1715 - val_accuracy: 0.9333\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.1684 - accuracy: 0.9417 - val_loss: 0.2340 - val_accuracy: 0.8000\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.2308 - accuracy: 0.9000 - val_loss: 0.1500 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.1714 - accuracy: 0.9583 - val_loss: 0.1507 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1589 - accuracy: 0.9667 - val_loss: 0.1836 - val_accuracy: 0.9667\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.1836 - accuracy: 0.9417 - val_loss: 0.1504 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1526 - accuracy: 0.9667 - val_loss: 0.1474 - val_accuracy: 0.9667\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.1534 - accuracy: 0.9667 - val_loss: 0.1379 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.1494 - accuracy: 0.9667 - val_loss: 0.1400 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.1546 - accuracy: 0.9667 - val_loss: 0.1357 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.1439 - accuracy: 0.9667 - val_loss: 0.1440 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.1525 - accuracy: 0.9583 - val_loss: 0.1358 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.1431 - accuracy: 0.9667 - val_loss: 0.1383 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.1468 - accuracy: 0.9750 - val_loss: 0.1430 - val_accuracy: 0.9667\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.1553 - accuracy: 0.9583 - val_loss: 0.1588 - val_accuracy: 0.9667\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.1663 - accuracy: 0.9500 - val_loss: 0.1427 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.1395 - accuracy: 0.9750 - val_loss: 0.2193 - val_accuracy: 0.8000\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.2047 - accuracy: 0.9167 - val_loss: 0.1584 - val_accuracy: 0.9333\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.1691 - accuracy: 0.9500 - val_loss: 0.1407 - val_accuracy: 0.9667\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.1511 - accuracy: 0.9667 - val_loss: 0.1629 - val_accuracy: 0.9667\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.1512 - accuracy: 0.9667 - val_loss: 0.2776 - val_accuracy: 0.8333\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.2592 - accuracy: 0.9000 - val_loss: 0.3151 - val_accuracy: 0.8000\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.3163 - accuracy: 0.8583 - val_loss: 0.1901 - val_accuracy: 0.9667\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.1922 - accuracy: 0.9417 - val_loss: 0.3197 - val_accuracy: 0.8333\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.2902 - accuracy: 0.8333 - val_loss: 0.1989 - val_accuracy: 0.9333\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.2017 - accuracy: 0.9417 - val_loss: 0.1431 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.1439 - accuracy: 0.9833 - val_loss: 0.2000 - val_accuracy: 0.9000\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.1961 - accuracy: 0.9417 - val_loss: 0.1470 - val_accuracy: 0.9667\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1465 - accuracy: 0.9667 - val_loss: 0.1699 - val_accuracy: 0.9333\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.1784 - accuracy: 0.9417 - val_loss: 0.1273 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.1439 - accuracy: 0.9750 - val_loss: 0.1334 - val_accuracy: 0.9667\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.1417 - accuracy: 0.9667 - val_loss: 0.1342 - val_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.1462 - accuracy: 0.9667 - val_loss: 0.1254 - val_accuracy: 0.9667\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.1376 - accuracy: 0.9583 - val_loss: 0.1280 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.1393 - accuracy: 0.9583 - val_loss: 0.1295 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.1416 - accuracy: 0.9583 - val_loss: 0.1231 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.1303 - accuracy: 0.9750 - val_loss: 0.1229 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.1299 - accuracy: 0.9750 - val_loss: 0.1231 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1330 - accuracy: 0.9750 - val_loss: 0.1357 - val_accuracy: 0.9667\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1399 - accuracy: 0.9667 - val_loss: 0.1313 - val_accuracy: 0.9667\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1383 - accuracy: 0.9667 - val_loss: 0.1318 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.1306 - accuracy: 0.9750 - val_loss: 0.1342 - val_accuracy: 0.9667\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1360 - accuracy: 0.9667 - val_loss: 0.1258 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.1285 - accuracy: 0.9750 - val_loss: 0.1228 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1259 - accuracy: 0.9833 - val_loss: 0.1211 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.1307 - accuracy: 0.9750 - val_loss: 0.1812 - val_accuracy: 0.9000\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.1905 - accuracy: 0.9417 - val_loss: 0.1354 - val_accuracy: 0.9667\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.1691 - accuracy: 0.9500 - val_loss: 0.1185 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.1320 - accuracy: 0.9667 - val_loss: 0.2424 - val_accuracy: 0.8667\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.2420 - accuracy: 0.8833 - val_loss: 0.1664 - val_accuracy: 0.9667\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.1667 - accuracy: 0.9500 - val_loss: 0.1270 - val_accuracy: 0.9667\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.1330 - accuracy: 0.9667 - val_loss: 0.1264 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.1289 - accuracy: 0.9667 - val_loss: 0.1200 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.1230 - accuracy: 0.9750 - val_loss: 0.1217 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.1247 - accuracy: 0.9750 - val_loss: 0.1217 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.1312 - accuracy: 0.9667 - val_loss: 0.1341 - val_accuracy: 0.9667\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.1408 - accuracy: 0.9667 - val_loss: 0.1198 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.1284 - accuracy: 0.9833 - val_loss: 0.1324 - val_accuracy: 0.9667\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.1345 - accuracy: 0.9667 - val_loss: 0.1230 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.1329 - accuracy: 0.9583 - val_loss: 0.1193 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.1280 - accuracy: 0.9750 - val_loss: 0.2113 - val_accuracy: 0.8000\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.2097 - accuracy: 0.9083 - val_loss: 0.1341 - val_accuracy: 0.9667\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.1337 - accuracy: 0.9750 - val_loss: 0.2177 - val_accuracy: 0.9000\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.1997 - accuracy: 0.9167 - val_loss: 0.1702 - val_accuracy: 0.9667\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.1820 - accuracy: 0.9250 - val_loss: 0.1166 - val_accuracy: 0.9667\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.1225 - accuracy: 0.9583 - val_loss: 0.2566 - val_accuracy: 0.8667\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.2538 - accuracy: 0.8917 - val_loss: 0.1516 - val_accuracy: 0.9667\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1603 - accuracy: 0.9583 - val_loss: 0.1119 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1329 - accuracy: 0.9667 - val_loss: 0.1117 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.1195 - accuracy: 0.9833 - val_loss: 0.1657 - val_accuracy: 0.9667\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.1615 - accuracy: 0.9417 - val_loss: 0.1346 - val_accuracy: 0.9667\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1353 - accuracy: 0.9667 - val_loss: 0.1168 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.1231 - accuracy: 0.9750 - val_loss: 0.1121 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.1191 - accuracy: 0.9667 - val_loss: 0.1097 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.1145 - accuracy: 0.9750 - val_loss: 0.1211 - val_accuracy: 0.9667\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.1259 - accuracy: 0.9667 - val_loss: 0.1190 - val_accuracy: 0.9667\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.1342 - accuracy: 0.9500 - val_loss: 0.1076 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.1244 - accuracy: 0.9750 - val_loss: 0.1109 - val_accuracy: 0.9667\n"
     ]
    }
   ],
   "source": [
    "#Construcción de la red neuronal\n",
    "\n",
    "# neural network structure\n",
    "model = Sequential()\n",
    "model.add(Dense(8, activation='relu', input_shape=(4,)))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "#Gradiente descendente\n",
    "learning_rate=0.1\n",
    "epochs = 200\n",
    "momentum = 0.8\n",
    "decay_rate = learning_rate/epochs\n",
    "sgd = SGD(lr=learning_rate, decay=decay_rate, momentum=momentum)\n",
    "\n",
    "# configuracion del optimizador\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# entrenamiento de la red neuronal\n",
    "#history = model.fit(X, dummy_y,epochs=200, batch_size=100, verbose=1)\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                   epochs=epochs, \n",
    "                   batch_size=100, \n",
    "                   validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Graficar el categorical crossentropy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax.plot(np.sqrt(history.history['loss']), 'r', label='train')\n",
    "ax.plot(np.sqrt(history.history['val_loss']), 'b' ,label='val')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Loss', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    }
   ],
   "source": [
    "#Predecir con el modelo\n",
    "#Y_pred = model.predict_classes(X)\n",
    "#Y_prob = model.predict_proba(X)\n",
    "\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "Y_prob = (model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.45017201e-07, 7.86734283e-01, 2.13265106e-01],\n",
       "       [9.60370302e-01, 3.95933129e-02, 3.64063781e-05],\n",
       "       [9.56054768e-24, 1.85824378e-04, 9.99814212e-01],\n",
       "       [2.52550961e-07, 7.44874120e-01, 2.55125612e-01],\n",
       "       [5.41331190e-07, 7.86385655e-01, 2.13613734e-01],\n",
       "       [9.60370302e-01, 3.95933129e-02, 3.64063781e-05],\n",
       "       [1.05708195e-02, 9.78184700e-01, 1.12444470e-02],\n",
       "       [2.25948687e-12, 1.08735383e-01, 8.91264558e-01],\n",
       "       [3.98130950e-09, 4.66579884e-01, 5.33420146e-01],\n",
       "       [6.98610558e-04, 9.72162127e-01, 2.71392968e-02],\n",
       "       [2.82568430e-11, 1.88849926e-01, 8.11150074e-01],\n",
       "       [9.60370302e-01, 3.95933129e-02, 3.64063781e-05],\n",
       "       [9.60370302e-01, 3.95933129e-02, 3.64063781e-05],\n",
       "       [9.60370302e-01, 3.95933129e-02, 3.64063781e-05],\n",
       "       [9.60370302e-01, 3.95933129e-02, 3.64063781e-05],\n",
       "       [5.43879537e-07, 7.86626935e-01, 2.13372499e-01],\n",
       "       [1.08948695e-17, 5.76697895e-03, 9.94232953e-01],\n",
       "       [2.11421691e-04, 9.60302711e-01, 3.94858345e-02],\n",
       "       [2.71506735e-07, 7.49009669e-01, 2.50990093e-01],\n",
       "       [2.03219830e-17, 6.72052521e-03, 9.93279517e-01],\n",
       "       [9.60370302e-01, 3.95933129e-02, 3.64063781e-05],\n",
       "       [1.26550367e-10, 2.56086111e-01, 7.43913889e-01],\n",
       "       [9.60370302e-01, 3.95933129e-02, 3.64063781e-05],\n",
       "       [8.19375336e-17, 9.45865363e-03, 9.90541279e-01],\n",
       "       [1.23358599e-13, 5.54541685e-02, 9.44545865e-01],\n",
       "       [6.69549119e-14, 4.79804911e-02, 9.52019572e-01],\n",
       "       [1.25153247e-16, 1.04919020e-02, 9.89508033e-01],\n",
       "       [2.17129104e-17, 6.83057960e-03, 9.93169427e-01],\n",
       "       [9.60370302e-01, 3.95933129e-02, 3.64063781e-05],\n",
       "       [9.60370302e-01, 3.95933129e-02, 3.64063744e-05]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reverse\n",
    "uniques, ids = np.unique(Y, return_inverse=True)\n",
    "dummy_y = np_utils.to_categorical(ids, len(uniques))\n",
    "reverse = uniques[dummy_y.argmax(1)]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, reverse,\n",
    "                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 2, 2, 1, 2, 1, 2,\n",
       "       1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 1, 2, 0, 1, 2, 0, 2, 2,\n",
       "       1, 1, 2, 1, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0, 0, 1, 1, 2, 1, 2, 2, 1,\n",
       "       0, 0, 2, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 1, 2, 1, 2, 0, 2, 1, 2,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 1, 2, 2, 1, 2,\n",
       "       1, 1, 2, 2, 0, 1, 2, 0, 1, 2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      " \t Accu \t Prec \t Reca\n",
      " Train \t 0.967 \t 0.970 \t 0.967\n",
      "  Test \t 0.967 \t 0.969 \t 0.967\n"
     ]
    }
   ],
   "source": [
    "#Más métricas corregido\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,f1_score)\n",
    "Y_proba= model.predict(X_train)\n",
    "Y_pred= np.argmax(Y_proba, axis=1)\n",
    "\n",
    "accu_train = accuracy_score(y_train, Y_pred)\n",
    "prec_train = precision_score(y_train, Y_pred,average='weighted')\n",
    "reca_train = recall_score(y_train, Y_pred,average='weighted')\n",
    "\n",
    "Y_proba= model.predict(X_test)\n",
    "Y_pred= np.argmax(Y_proba, axis=1)\n",
    "\n",
    "accu_test = accuracy_score(y_test, Y_pred)\n",
    "prec_test = precision_score(y_test, Y_pred,average='weighted')\n",
    "reca_test = recall_score(y_test, Y_pred,average='weighted')\n",
    "print(' \\t Accu \\t Prec \\t Reca\\n Train \\t %0.3f \\t %0.3f \\t %0.3f\\n  Test \\t %0.3f \\t %0.3f \\t %0.3f'%(accu_train,prec_train,reca_train,accu_test,prec_test,reca_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \t Accu \t Prec \t Reca\n",
      " Train \t 0.975 \t 0.977 \t 0.975\n",
      "  Test \t 1.000 \t 1.000 \t 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09090\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Comparar contra Regresión logística\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_log = LogisticRegression()\n",
    "model_log.fit(X_train,y_train)\n",
    "Yhat = model_log.predict(X_test)\n",
    "\n",
    "accu_train = accuracy_score(y_train,model_log.predict(X_train))\n",
    "prec_train = precision_score(y_train,model_log.predict(X_train),average='weighted')\n",
    "reca_train = recall_score(y_train,model_log.predict(X_train),average='weighted')\n",
    "\n",
    "accu_test = accuracy_score(y_test,model_log.predict(X_test))\n",
    "prec_test = precision_score(y_test,model_log.predict(X_test),average='weighted')\n",
    "reca_test = recall_score(y_test,model_log.predict(X_test),average='weighted')\n",
    "\n",
    "print(' \\t Accu \\t Prec \\t Reca\\n Train \\t %0.3f \\t %0.3f \\t %0.3f\\n  Test \\t %0.3f \\t %0.3f \\t %0.3f'%(accu_train,prec_train,reca_train,accu_test,prec_test,reca_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
